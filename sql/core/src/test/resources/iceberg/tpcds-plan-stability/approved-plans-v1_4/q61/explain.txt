== Physical Plan ==
* Project (63)
+- * BroadcastNestedLoopJoin Inner BuildRight (62)
   :- * HashAggregate (39)
   :  +- Exchange (38)
   :     +- * HashAggregate (37)
   :        +- * Project (36)
   :           +- * BroadcastHashJoin Inner BuildRight (35)
   :              :- * Project (30)
   :              :  +- * BroadcastHashJoin Inner BuildRight (29)
   :              :     :- * Project (24)
   :              :     :  +- * BroadcastHashJoin Inner BuildRight (23)
   :              :     :     :- * Project (18)
   :              :     :     :  +- * BroadcastHashJoin Inner BuildRight (17)
   :              :     :     :     :- * Project (15)
   :              :     :     :     :  +- * BroadcastHashJoin Inner BuildRight (14)
   :              :     :     :     :     :- * Project (9)
   :              :     :     :     :     :  +- * BroadcastHashJoin Inner BuildRight (8)
   :              :     :     :     :     :     :- * Project (3)
   :              :     :     :     :     :     :  +- * Filter (2)
   :              :     :     :     :     :     :     +- BatchScan spark_catalog.default.store_sales (1)
   :              :     :     :     :     :     +- BroadcastExchange (7)
   :              :     :     :     :     :        +- * Project (6)
   :              :     :     :     :     :           +- * Filter (5)
   :              :     :     :     :     :              +- BatchScan spark_catalog.default.store (4)
   :              :     :     :     :     +- BroadcastExchange (13)
   :              :     :     :     :        +- * Project (12)
   :              :     :     :     :           +- * Filter (11)
   :              :     :     :     :              +- BatchScan spark_catalog.default.promotion (10)
   :              :     :     :     +- ReusedExchange (16)
   :              :     :     +- BroadcastExchange (22)
   :              :     :        +- * Project (21)
   :              :     :           +- * Filter (20)
   :              :     :              +- BatchScan spark_catalog.default.customer (19)
   :              :     +- BroadcastExchange (28)
   :              :        +- * Project (27)
   :              :           +- * Filter (26)
   :              :              +- BatchScan spark_catalog.default.customer_address (25)
   :              +- BroadcastExchange (34)
   :                 +- * Project (33)
   :                    +- * Filter (32)
   :                       +- BatchScan spark_catalog.default.item (31)
   +- BroadcastExchange (61)
      +- * HashAggregate (60)
         +- Exchange (59)
            +- * HashAggregate (58)
               +- * Project (57)
                  +- * BroadcastHashJoin Inner BuildRight (56)
                     :- * Project (54)
                     :  +- * BroadcastHashJoin Inner BuildRight (53)
                     :     :- * Project (51)
                     :     :  +- * BroadcastHashJoin Inner BuildRight (50)
                     :     :     :- * Project (48)
                     :     :     :  +- * BroadcastHashJoin Inner BuildRight (47)
                     :     :     :     :- * Project (45)
                     :     :     :     :  +- * BroadcastHashJoin Inner BuildRight (44)
                     :     :     :     :     :- * Project (42)
                     :     :     :     :     :  +- * Filter (41)
                     :     :     :     :     :     +- BatchScan spark_catalog.default.store_sales (40)
                     :     :     :     :     +- ReusedExchange (43)
                     :     :     :     +- ReusedExchange (46)
                     :     :     +- ReusedExchange (49)
                     :     +- ReusedExchange (52)
                     +- ReusedExchange (55)


(1) BatchScan spark_catalog.default.store_sales
Output [6]: [ss_sold_date_sk#1, ss_item_sk#2, ss_customer_sk#3, ss_store_sk#4, ss_promo_sk#5, ss_ext_sales_price#6]
spark_catalog.default.store_sales [scan class = SparkBatchQueryScan] [filters=ss_store_sk IS NOT NULL, ss_promo_sk IS NOT NULL, ss_sold_date_sk IS NOT NULL, ss_customer_sk IS NOT NULL, ss_item_sk IS NOT NULL], [runtimeFilters=[]], caseSensitive=false,[ Broadcast Var UNUSED =]

(2) Filter [codegen id : 7]
Input [6]: [ss_sold_date_sk#1, ss_item_sk#2, ss_customer_sk#3, ss_store_sk#4, ss_promo_sk#5, ss_ext_sales_price#6]
Condition : ((((isnotnull(ss_store_sk#4) AND isnotnull(ss_promo_sk#5)) AND isnotnull(ss_sold_date_sk#1)) AND isnotnull(ss_customer_sk#3)) AND isnotnull(ss_item_sk#2))

(3) Project [codegen id : 7]
Output [6]: [ss_sold_date_sk#1, ss_item_sk#2, ss_customer_sk#3, ss_store_sk#4, ss_promo_sk#5, ss_ext_sales_price#6]
Input [6]: [ss_sold_date_sk#1, ss_item_sk#2, ss_customer_sk#3, ss_store_sk#4, ss_promo_sk#5, ss_ext_sales_price#6]

(4) BatchScan spark_catalog.default.store
Output [2]: [s_store_sk#7, s_gmt_offset#8]
spark_catalog.default.store [scan class = SparkBatchQueryScan] [filters=s_gmt_offset IS NOT NULL, s_gmt_offset = -5.00, s_store_sk IS NOT NULL], [runtimeFilters=[]], caseSensitive=false,[ Broadcast Var UNUSED =]

(5) Filter [codegen id : 1]
Input [2]: [s_store_sk#7, s_gmt_offset#8]
Condition : ((isnotnull(s_gmt_offset#8) AND (s_gmt_offset#8 = -5.00)) AND isnotnull(s_store_sk#7))

(6) Project [codegen id : 1]
Output [1]: [s_store_sk#7]
Input [2]: [s_store_sk#7, s_gmt_offset#8]

(7) BroadcastExchange
Input [1]: [s_store_sk#7]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=1]

(8) BroadcastHashJoin [codegen id : 7]
Left keys [1]: [ss_store_sk#4]
Right keys [1]: [s_store_sk#7]
Join condition: None

(9) Project [codegen id : 7]
Output [5]: [ss_sold_date_sk#1, ss_item_sk#2, ss_customer_sk#3, ss_promo_sk#5, ss_ext_sales_price#6]
Input [7]: [ss_sold_date_sk#1, ss_item_sk#2, ss_customer_sk#3, ss_store_sk#4, ss_promo_sk#5, ss_ext_sales_price#6, s_store_sk#7]

(10) BatchScan spark_catalog.default.promotion
Output [4]: [p_promo_sk#9, p_channel_dmail#10, p_channel_email#11, p_channel_tv#12]
spark_catalog.default.promotion [scan class = SparkBatchQueryScan] [filters=((p_channel_dmail = 'Y' OR p_channel_email = 'Y') OR p_channel_tv = 'Y'), p_promo_sk IS NOT NULL], [runtimeFilters=[]], caseSensitive=false,[ Broadcast Var UNUSED =]

(11) Filter [codegen id : 2]
Input [4]: [p_promo_sk#9, p_channel_dmail#10, p_channel_email#11, p_channel_tv#12]
Condition : ((((p_channel_dmail#10 = Y) OR (p_channel_email#11 = Y)) OR (p_channel_tv#12 = Y)) AND isnotnull(p_promo_sk#9))

(12) Project [codegen id : 2]
Output [1]: [p_promo_sk#9]
Input [4]: [p_promo_sk#9, p_channel_dmail#10, p_channel_email#11, p_channel_tv#12]

(13) BroadcastExchange
Input [1]: [p_promo_sk#9]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=2]

(14) BroadcastHashJoin [codegen id : 7]
Left keys [1]: [ss_promo_sk#5]
Right keys [1]: [p_promo_sk#9]
Join condition: None

(15) Project [codegen id : 7]
Output [4]: [ss_sold_date_sk#1, ss_item_sk#2, ss_customer_sk#3, ss_ext_sales_price#6]
Input [6]: [ss_sold_date_sk#1, ss_item_sk#2, ss_customer_sk#3, ss_promo_sk#5, ss_ext_sales_price#6, p_promo_sk#9]

(16) ReusedExchange [Reuses operator id: 67]
Output [1]: [d_date_sk#13]

(17) BroadcastHashJoin [codegen id : 7]
Left keys [1]: [ss_sold_date_sk#1]
Right keys [1]: [d_date_sk#13]
Join condition: None

(18) Project [codegen id : 7]
Output [3]: [ss_item_sk#2, ss_customer_sk#3, ss_ext_sales_price#6]
Input [5]: [ss_sold_date_sk#1, ss_item_sk#2, ss_customer_sk#3, ss_ext_sales_price#6, d_date_sk#13]

(19) BatchScan spark_catalog.default.customer
Output [2]: [c_customer_sk#14, c_current_addr_sk#15]
spark_catalog.default.customer [scan class = SparkBatchQueryScan] [filters=c_customer_sk IS NOT NULL, c_current_addr_sk IS NOT NULL], [runtimeFilters=[]], caseSensitive=false,[ Broadcast Var UNUSED =]

(20) Filter [codegen id : 4]
Input [2]: [c_customer_sk#14, c_current_addr_sk#15]
Condition : (isnotnull(c_customer_sk#14) AND isnotnull(c_current_addr_sk#15))

(21) Project [codegen id : 4]
Output [2]: [c_customer_sk#14, c_current_addr_sk#15]
Input [2]: [c_customer_sk#14, c_current_addr_sk#15]

(22) BroadcastExchange
Input [2]: [c_customer_sk#14, c_current_addr_sk#15]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=3]

(23) BroadcastHashJoin [codegen id : 7]
Left keys [1]: [ss_customer_sk#3]
Right keys [1]: [c_customer_sk#14]
Join condition: None

(24) Project [codegen id : 7]
Output [3]: [ss_item_sk#2, ss_ext_sales_price#6, c_current_addr_sk#15]
Input [5]: [ss_item_sk#2, ss_customer_sk#3, ss_ext_sales_price#6, c_customer_sk#14, c_current_addr_sk#15]

(25) BatchScan spark_catalog.default.customer_address
Output [2]: [ca_address_sk#16, ca_gmt_offset#17]
spark_catalog.default.customer_address [scan class = SparkBatchQueryScan] [filters=ca_gmt_offset IS NOT NULL, ca_gmt_offset = -5.00, ca_address_sk IS NOT NULL], [runtimeFilters=[]], caseSensitive=false,[ Broadcast Var UNUSED =]

(26) Filter [codegen id : 5]
Input [2]: [ca_address_sk#16, ca_gmt_offset#17]
Condition : ((isnotnull(ca_gmt_offset#17) AND (ca_gmt_offset#17 = -5.00)) AND isnotnull(ca_address_sk#16))

(27) Project [codegen id : 5]
Output [1]: [ca_address_sk#16]
Input [2]: [ca_address_sk#16, ca_gmt_offset#17]

(28) BroadcastExchange
Input [1]: [ca_address_sk#16]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=4]

(29) BroadcastHashJoin [codegen id : 7]
Left keys [1]: [c_current_addr_sk#15]
Right keys [1]: [ca_address_sk#16]
Join condition: None

(30) Project [codegen id : 7]
Output [2]: [ss_item_sk#2, ss_ext_sales_price#6]
Input [4]: [ss_item_sk#2, ss_ext_sales_price#6, c_current_addr_sk#15, ca_address_sk#16]

(31) BatchScan spark_catalog.default.item
Output [2]: [i_item_sk#18, i_category#19]
spark_catalog.default.item [scan class = SparkBatchQueryScan] [filters=i_category IS NOT NULL, i_category = 'Jewelry', i_item_sk IS NOT NULL], [runtimeFilters=[]], caseSensitive=false,[ Broadcast Var UNUSED =]

(32) Filter [codegen id : 6]
Input [2]: [i_item_sk#18, i_category#19]
Condition : ((isnotnull(i_category#19) AND (i_category#19 = Jewelry)) AND isnotnull(i_item_sk#18))

(33) Project [codegen id : 6]
Output [1]: [i_item_sk#18]
Input [2]: [i_item_sk#18, i_category#19]

(34) BroadcastExchange
Input [1]: [i_item_sk#18]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=5]

(35) BroadcastHashJoin [codegen id : 7]
Left keys [1]: [ss_item_sk#2]
Right keys [1]: [i_item_sk#18]
Join condition: None

(36) Project [codegen id : 7]
Output [1]: [ss_ext_sales_price#6]
Input [3]: [ss_item_sk#2, ss_ext_sales_price#6, i_item_sk#18]

(37) HashAggregate [codegen id : 7]
Input [1]: [ss_ext_sales_price#6]
Keys: []
Functions [1]: [partial_sum(UnscaledValue(ss_ext_sales_price#6))]
Aggregate Attributes [1]: [sum#20]
Results [1]: [sum#21]

(38) Exchange
Input [1]: [sum#21]
Arguments: SinglePartition, ENSURE_REQUIREMENTS, [plan_id=6]

(39) HashAggregate [codegen id : 15]
Input [1]: [sum#21]
Keys: []
Functions [1]: [sum(UnscaledValue(ss_ext_sales_price#6))]
Aggregate Attributes [1]: [sum(UnscaledValue(ss_ext_sales_price#6))#22]
Results [1]: [MakeDecimal(sum(UnscaledValue(ss_ext_sales_price#6))#22,17,2) AS promotions#23]

(40) BatchScan spark_catalog.default.store_sales
Output [5]: [ss_sold_date_sk#24, ss_item_sk#25, ss_customer_sk#26, ss_store_sk#27, ss_ext_sales_price#28]
spark_catalog.default.store_sales [scan class = SparkBatchQueryScan] [filters=ss_store_sk IS NOT NULL, ss_sold_date_sk IS NOT NULL, ss_customer_sk IS NOT NULL, ss_item_sk IS NOT NULL], [runtimeFilters=[]], caseSensitive=false,[ Broadcast Var UNUSED =]

(41) Filter [codegen id : 13]
Input [5]: [ss_sold_date_sk#24, ss_item_sk#25, ss_customer_sk#26, ss_store_sk#27, ss_ext_sales_price#28]
Condition : (((isnotnull(ss_store_sk#27) AND isnotnull(ss_sold_date_sk#24)) AND isnotnull(ss_customer_sk#26)) AND isnotnull(ss_item_sk#25))

(42) Project [codegen id : 13]
Output [5]: [ss_sold_date_sk#24, ss_item_sk#25, ss_customer_sk#26, ss_store_sk#27, ss_ext_sales_price#28]
Input [5]: [ss_sold_date_sk#24, ss_item_sk#25, ss_customer_sk#26, ss_store_sk#27, ss_ext_sales_price#28]

(43) ReusedExchange [Reuses operator id: 7]
Output [1]: [s_store_sk#29]

(44) BroadcastHashJoin [codegen id : 13]
Left keys [1]: [ss_store_sk#27]
Right keys [1]: [s_store_sk#29]
Join condition: None

(45) Project [codegen id : 13]
Output [4]: [ss_sold_date_sk#24, ss_item_sk#25, ss_customer_sk#26, ss_ext_sales_price#28]
Input [6]: [ss_sold_date_sk#24, ss_item_sk#25, ss_customer_sk#26, ss_store_sk#27, ss_ext_sales_price#28, s_store_sk#29]

(46) ReusedExchange [Reuses operator id: 67]
Output [1]: [d_date_sk#30]

(47) BroadcastHashJoin [codegen id : 13]
Left keys [1]: [ss_sold_date_sk#24]
Right keys [1]: [d_date_sk#30]
Join condition: None

(48) Project [codegen id : 13]
Output [3]: [ss_item_sk#25, ss_customer_sk#26, ss_ext_sales_price#28]
Input [5]: [ss_sold_date_sk#24, ss_item_sk#25, ss_customer_sk#26, ss_ext_sales_price#28, d_date_sk#30]

(49) ReusedExchange [Reuses operator id: 22]
Output [2]: [c_customer_sk#31, c_current_addr_sk#32]

(50) BroadcastHashJoin [codegen id : 13]
Left keys [1]: [ss_customer_sk#26]
Right keys [1]: [c_customer_sk#31]
Join condition: None

(51) Project [codegen id : 13]
Output [3]: [ss_item_sk#25, ss_ext_sales_price#28, c_current_addr_sk#32]
Input [5]: [ss_item_sk#25, ss_customer_sk#26, ss_ext_sales_price#28, c_customer_sk#31, c_current_addr_sk#32]

(52) ReusedExchange [Reuses operator id: 28]
Output [1]: [ca_address_sk#33]

(53) BroadcastHashJoin [codegen id : 13]
Left keys [1]: [c_current_addr_sk#32]
Right keys [1]: [ca_address_sk#33]
Join condition: None

(54) Project [codegen id : 13]
Output [2]: [ss_item_sk#25, ss_ext_sales_price#28]
Input [4]: [ss_item_sk#25, ss_ext_sales_price#28, c_current_addr_sk#32, ca_address_sk#33]

(55) ReusedExchange [Reuses operator id: 34]
Output [1]: [i_item_sk#34]

(56) BroadcastHashJoin [codegen id : 13]
Left keys [1]: [ss_item_sk#25]
Right keys [1]: [i_item_sk#34]
Join condition: None

(57) Project [codegen id : 13]
Output [1]: [ss_ext_sales_price#28]
Input [3]: [ss_item_sk#25, ss_ext_sales_price#28, i_item_sk#34]

(58) HashAggregate [codegen id : 13]
Input [1]: [ss_ext_sales_price#28]
Keys: []
Functions [1]: [partial_sum(UnscaledValue(ss_ext_sales_price#28))]
Aggregate Attributes [1]: [sum#35]
Results [1]: [sum#36]

(59) Exchange
Input [1]: [sum#36]
Arguments: SinglePartition, ENSURE_REQUIREMENTS, [plan_id=7]

(60) HashAggregate [codegen id : 14]
Input [1]: [sum#36]
Keys: []
Functions [1]: [sum(UnscaledValue(ss_ext_sales_price#28))]
Aggregate Attributes [1]: [sum(UnscaledValue(ss_ext_sales_price#28))#37]
Results [1]: [MakeDecimal(sum(UnscaledValue(ss_ext_sales_price#28))#37,17,2) AS total#38]

(61) BroadcastExchange
Input [1]: [total#38]
Arguments: IdentityBroadcastMode, [plan_id=8]

(62) BroadcastNestedLoopJoin [codegen id : 15]
Join condition: None

(63) Project [codegen id : 15]
Output [3]: [promotions#23, total#38, CheckOverflow((promote_precision(CheckOverflow((promote_precision(cast(promotions#23 as decimal(15,4))) / promote_precision(cast(total#38 as decimal(15,4)))), DecimalType(35,20))) * 100.00000000000000000000), DecimalType(38,19)) AS ((CAST(promotions AS DECIMAL(15,4)) / CAST(total AS DECIMAL(15,4))) * 100)#39]
Input [2]: [promotions#23, total#38]

===== Subqueries =====

Subquery:1 Hosting operator id = 1 Hosting Expression = ss_sold_date_sk#1 IN dynamicpruning#40
BroadcastExchange (67)
+- * Project (66)
   +- * Filter (65)
      +- BatchScan spark_catalog.default.date_dim (64)


(64) BatchScan spark_catalog.default.date_dim
Output [3]: [d_date_sk#13, d_year#41, d_moy#42]
spark_catalog.default.date_dim [scan class = SparkBatchQueryScan] [filters=d_year IS NOT NULL, d_moy IS NOT NULL, d_year = 1998, d_moy = 11, d_date_sk IS NOT NULL], [runtimeFilters=[]], caseSensitive=false,[ Broadcast Var UNUSED =]

(65) Filter [codegen id : 1]
Input [3]: [d_date_sk#13, d_year#41, d_moy#42]
Condition : ((((isnotnull(d_year#41) AND isnotnull(d_moy#42)) AND (d_year#41 = 1998)) AND (d_moy#42 = 11)) AND isnotnull(d_date_sk#13))

(66) Project [codegen id : 1]
Output [1]: [d_date_sk#13]
Input [3]: [d_date_sk#13, d_year#41, d_moy#42]

(67) BroadcastExchange
Input [1]: [d_date_sk#13]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=9]

Subquery:2 Hosting operator id = 40 Hosting Expression = ss_sold_date_sk#24 IN dynamicpruning#40


