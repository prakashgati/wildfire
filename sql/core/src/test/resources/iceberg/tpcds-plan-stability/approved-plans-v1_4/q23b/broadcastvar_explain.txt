== Physical Plan ==
TakeOrderedAndProject (77)
+- Union (76)
   :- * HashAggregate (53)
   :  +- Exchange (52)
   :     +- * HashAggregate (51)
   :        +- * Project (50)
   :           +- * BroadcastHashJoin Inner BuildRight (49)
   :              :- * Project (47)
   :              :  +- * BroadcastHashJoin Inner BuildRight (46)
   :              :     :- * BroadcastHashJoin LeftSemi BuildRight (39)
   :              :     :  :- * Project (23)
   :              :     :  :  +- * BroadcastHashJoin LeftSemi BuildRight (22)
   :              :     :  :     :- * Project (3)
   :              :     :  :     :  +- * Filter (2)
   :              :     :  :     :     +- BatchScan spark_catalog.default.catalog_sales (1)
   :              :     :  :     +- BroadcastExchange (21)
   :              :     :  :        +- * Project (20)
   :              :     :  :           +- * Filter (19)
   :              :     :  :              +- * HashAggregate (18)
   :              :     :  :                 +- Exchange (17)
   :              :     :  :                    +- * HashAggregate (16)
   :              :     :  :                       +- * Project (15)
   :              :     :  :                          +- * BroadcastHashJoin Inner BuildRight (14)
   :              :     :  :                             :- * Project (9)
   :              :     :  :                             :  +- * BroadcastHashJoin Inner BuildRight (8)
   :              :     :  :                             :     :- * Project (6)
   :              :     :  :                             :     :  +- * Filter (5)
   :              :     :  :                             :     :     +- BatchScan spark_catalog.default.store_sales (4)
   :              :     :  :                             :     +- ReusedExchange (7)
   :              :     :  :                             +- BroadcastExchange (13)
   :              :     :  :                                +- * Project (12)
   :              :     :  :                                   +- * Filter (11)
   :              :     :  :                                      +- BatchScan spark_catalog.default.item (10)
   :              :     :  +- BroadcastExchange (38)
   :              :     :     +- * Project (37)
   :              :     :        +- * Filter (36)
   :              :     :           +- * HashAggregate (35)
   :              :     :              +- Exchange (34)
   :              :     :                 +- * HashAggregate (33)
   :              :     :                    +- * Project (32)
   :              :     :                       +- * BroadcastHashJoin Inner BuildRight (31)
   :              :     :                          :- * Project (26)
   :              :     :                          :  +- * Filter (25)
   :              :     :                          :     +- BatchScan spark_catalog.default.store_sales (24)
   :              :     :                          +- BroadcastExchange (30)
   :              :     :                             +- * Project (29)
   :              :     :                                +- * Filter (28)
   :              :     :                                   +- BatchScan spark_catalog.default.customer (27)
   :              :     +- BroadcastExchange (45)
   :              :        +- * BroadcastHashJoin LeftSemi BuildRight (44)
   :              :           :- * Project (42)
   :              :           :  +- * Filter (41)
   :              :           :     +- BatchScan spark_catalog.default.customer (40)
   :              :           +- ReusedExchange (43)
   :              +- ReusedExchange (48)
   +- * HashAggregate (75)
      +- Exchange (74)
         +- * HashAggregate (73)
            +- * Project (72)
               +- * BroadcastHashJoin Inner BuildRight (71)
                  :- * Project (69)
                  :  +- * BroadcastHashJoin Inner BuildRight (68)
                  :     :- * BroadcastHashJoin LeftSemi BuildRight (61)
                  :     :  :- * Project (59)
                  :     :  :  +- * BroadcastHashJoin LeftSemi BuildRight (58)
                  :     :  :     :- * Project (56)
                  :     :  :     :  +- * Filter (55)
                  :     :  :     :     +- BatchScan spark_catalog.default.web_sales (54)
                  :     :  :     +- ReusedExchange (57)
                  :     :  +- ReusedExchange (60)
                  :     +- BroadcastExchange (67)
                  :        +- * BroadcastHashJoin LeftSemi BuildRight (66)
                  :           :- * Project (64)
                  :           :  +- * Filter (63)
                  :           :     +- BatchScan spark_catalog.default.customer (62)
                  :           +- ReusedExchange (65)
                  +- ReusedExchange (70)


(1) BatchScan spark_catalog.default.catalog_sales
Output [5]: [cs_sold_date_sk#1, cs_bill_customer_sk#2, cs_item_sk#3, cs_quantity#4, cs_list_price#5]
spark_catalog.default.catalog_sales [scan class = SparkBatchQueryScan] [filters=cs_bill_customer_sk IS NOT NULL, cs_sold_date_sk IS NOT NULL], [runtimeFilters=[]], caseSensitive=false,[ Broadcast Var UNUSED =]

(2) Filter [codegen id : 13]
Input [5]: [cs_sold_date_sk#1, cs_bill_customer_sk#2, cs_item_sk#3, cs_quantity#4, cs_list_price#5]
Condition : (isnotnull(cs_bill_customer_sk#2) AND isnotnull(cs_sold_date_sk#1))

(3) Project [codegen id : 13]
Output [5]: [cs_sold_date_sk#1, cs_bill_customer_sk#2, cs_item_sk#3, cs_quantity#4, cs_list_price#5]
Input [5]: [cs_sold_date_sk#1, cs_bill_customer_sk#2, cs_item_sk#3, cs_quantity#4, cs_list_price#5]

(4) BatchScan spark_catalog.default.store_sales
Output [2]: [ss_sold_date_sk#6, ss_item_sk#7]
spark_catalog.default.store_sales [scan class = SparkBatchQueryScan] [filters=ss_sold_date_sk IS NOT NULL, ss_item_sk IS NOT NULL], [runtimeFilters=[]], caseSensitive=false,[ Broadcast Var UNUSED =]

(5) Filter [codegen id : 3]
Input [2]: [ss_sold_date_sk#6, ss_item_sk#7]
Condition : (isnotnull(ss_sold_date_sk#6) AND isnotnull(ss_item_sk#7))

(6) Project [codegen id : 3]
Output [2]: [ss_sold_date_sk#6, ss_item_sk#7]
Input [2]: [ss_sold_date_sk#6, ss_item_sk#7]

(7) ReusedExchange [Reuses operator id: 85]
Output [2]: [d_date_sk#8, d_date#9]

(8) BroadcastHashJoin [codegen id : 3]
Left keys [1]: [ss_sold_date_sk#6]
Right keys [1]: [d_date_sk#8]
Join condition: None

(9) Project [codegen id : 3]
Output [2]: [ss_item_sk#7, d_date#9]
Input [4]: [ss_sold_date_sk#6, ss_item_sk#7, d_date_sk#8, d_date#9]

(10) BatchScan spark_catalog.default.item
Output [2]: [i_item_sk#10, i_item_desc#11]
spark_catalog.default.item [scan class = SparkBatchQueryScan] [filters=i_item_sk IS NOT NULL], [runtimeFilters=[]], caseSensitive=false,[ Broadcast Var UNUSED =]

(11) Filter [codegen id : 2]
Input [2]: [i_item_sk#10, i_item_desc#11]
Condition : isnotnull(i_item_sk#10)

(12) Project [codegen id : 2]
Output [2]: [i_item_sk#10, i_item_desc#11]
Input [2]: [i_item_sk#10, i_item_desc#11]

(13) BroadcastExchange
Input [2]: [i_item_sk#10, i_item_desc#11]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=1]

(14) BroadcastHashJoin [codegen id : 3]
Left keys [1]: [ss_item_sk#7]
Right keys [1]: [i_item_sk#10]
Join condition: None

(15) Project [codegen id : 3]
Output [3]: [d_date#9, i_item_sk#10, substr(i_item_desc#11, 1, 30) AS _groupingexpression#12]
Input [4]: [ss_item_sk#7, d_date#9, i_item_sk#10, i_item_desc#11]

(16) HashAggregate [codegen id : 3]
Input [3]: [d_date#9, i_item_sk#10, _groupingexpression#12]
Keys [3]: [_groupingexpression#12, i_item_sk#10, d_date#9]
Functions [1]: [partial_count(1)]
Aggregate Attributes [1]: [count#13]
Results [4]: [_groupingexpression#12, i_item_sk#10, d_date#9, count#14]

(17) Exchange
Input [4]: [_groupingexpression#12, i_item_sk#10, d_date#9, count#14]
Arguments: hashpartitioning(_groupingexpression#12, i_item_sk#10, d_date#9, 5), ENSURE_REQUIREMENTS, [plan_id=2]

(18) HashAggregate [codegen id : 4]
Input [4]: [_groupingexpression#12, i_item_sk#10, d_date#9, count#14]
Keys [3]: [_groupingexpression#12, i_item_sk#10, d_date#9]
Functions [1]: [count(1)]
Aggregate Attributes [1]: [count(1)#15]
Results [2]: [i_item_sk#10 AS item_sk#16, count(1)#15 AS cnt#17]

(19) Filter [codegen id : 4]
Input [2]: [item_sk#16, cnt#17]
Condition : (cnt#17 > 4)

(20) Project [codegen id : 4]
Output [1]: [item_sk#16]
Input [2]: [item_sk#16, cnt#17]

(21) BroadcastExchange
Input [1]: [item_sk#16]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=3]

(22) BroadcastHashJoin [codegen id : 13]
Left keys [1]: [cs_item_sk#3]
Right keys [1]: [item_sk#16]
Join condition: None

(23) Project [codegen id : 13]
Output [4]: [cs_sold_date_sk#1, cs_bill_customer_sk#2, cs_quantity#4, cs_list_price#5]
Input [5]: [cs_sold_date_sk#1, cs_bill_customer_sk#2, cs_item_sk#3, cs_quantity#4, cs_list_price#5]

(24) BatchScan spark_catalog.default.store_sales
Output [3]: [ss_customer_sk#18, ss_quantity#19, ss_sales_price#20]
spark_catalog.default.store_sales [scan class = SparkBatchQueryScan] [filters=ss_customer_sk IS NOT NULL], [runtimeFilters=[]], caseSensitive=false,[ Broadcast Var UNUSED =]

(25) Filter [codegen id : 6]
Input [3]: [ss_customer_sk#18, ss_quantity#19, ss_sales_price#20]
Condition : isnotnull(ss_customer_sk#18)

(26) Project [codegen id : 6]
Output [3]: [ss_customer_sk#18, ss_quantity#19, ss_sales_price#20]
Input [3]: [ss_customer_sk#18, ss_quantity#19, ss_sales_price#20]

(27) BatchScan spark_catalog.default.customer
Output [1]: [c_customer_sk#21]
spark_catalog.default.customer [scan class = SparkBatchQueryScan] [filters=c_customer_sk IS NOT NULL], [runtimeFilters=[]], caseSensitive=false,[ Broadcast Var UNUSED =]

(28) Filter [codegen id : 5]
Input [1]: [c_customer_sk#21]
Condition : isnotnull(c_customer_sk#21)

(29) Project [codegen id : 5]
Output [1]: [c_customer_sk#21]
Input [1]: [c_customer_sk#21]

(30) BroadcastExchange
Input [1]: [c_customer_sk#21]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=4]

(31) BroadcastHashJoin [codegen id : 6]
Left keys [1]: [ss_customer_sk#18]
Right keys [1]: [c_customer_sk#21]
Join condition: None

(32) Project [codegen id : 6]
Output [3]: [ss_quantity#19, ss_sales_price#20, c_customer_sk#21]
Input [4]: [ss_customer_sk#18, ss_quantity#19, ss_sales_price#20, c_customer_sk#21]

(33) HashAggregate [codegen id : 6]
Input [3]: [ss_quantity#19, ss_sales_price#20, c_customer_sk#21]
Keys [1]: [c_customer_sk#21]
Functions [1]: [partial_sum(CheckOverflow((promote_precision(cast(ss_quantity#19 as decimal(12,2))) * promote_precision(cast(ss_sales_price#20 as decimal(12,2)))), DecimalType(18,2)))]
Aggregate Attributes [2]: [sum#22, isEmpty#23]
Results [3]: [c_customer_sk#21, sum#24, isEmpty#25]

(34) Exchange
Input [3]: [c_customer_sk#21, sum#24, isEmpty#25]
Arguments: hashpartitioning(c_customer_sk#21, 5), ENSURE_REQUIREMENTS, [plan_id=5]

(35) HashAggregate [codegen id : 7]
Input [3]: [c_customer_sk#21, sum#24, isEmpty#25]
Keys [1]: [c_customer_sk#21]
Functions [1]: [sum(CheckOverflow((promote_precision(cast(ss_quantity#19 as decimal(12,2))) * promote_precision(cast(ss_sales_price#20 as decimal(12,2)))), DecimalType(18,2)))]
Aggregate Attributes [1]: [sum(CheckOverflow((promote_precision(cast(ss_quantity#19 as decimal(12,2))) * promote_precision(cast(ss_sales_price#20 as decimal(12,2)))), DecimalType(18,2)))#26]
Results [2]: [c_customer_sk#21, sum(CheckOverflow((promote_precision(cast(ss_quantity#19 as decimal(12,2))) * promote_precision(cast(ss_sales_price#20 as decimal(12,2)))), DecimalType(18,2)))#26 AS ssales#27]

(36) Filter [codegen id : 7]
Input [2]: [c_customer_sk#21, ssales#27]
Condition : (isnotnull(ssales#27) AND (cast(ssales#27 as decimal(38,8)) > CheckOverflow((0.500000 * promote_precision(cast(Subquery scalar-subquery#28, [id=#29] as decimal(32,6)))), DecimalType(38,8))))

(37) Project [codegen id : 7]
Output [1]: [c_customer_sk#21]
Input [2]: [c_customer_sk#21, ssales#27]

(38) BroadcastExchange
Input [1]: [c_customer_sk#21]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=6]

(39) BroadcastHashJoin [codegen id : 13]
Left keys [1]: [cs_bill_customer_sk#2]
Right keys [1]: [c_customer_sk#21]
Join condition: None

(40) BatchScan spark_catalog.default.customer
Output [3]: [c_customer_sk#30, c_first_name#31, c_last_name#32]
spark_catalog.default.customer [scan class = SparkBatchQueryScan] [filters=c_customer_sk IS NOT NULL], [runtimeFilters=[]], caseSensitive=false,[ Broadcast Var UNUSED =]

(41) Filter [codegen id : 11]
Input [3]: [c_customer_sk#30, c_first_name#31, c_last_name#32]
Condition : isnotnull(c_customer_sk#30)

(42) Project [codegen id : 11]
Output [3]: [c_customer_sk#30, c_first_name#31, c_last_name#32]
Input [3]: [c_customer_sk#30, c_first_name#31, c_last_name#32]

(43) ReusedExchange [Reuses operator id: 38]
Output [1]: [c_customer_sk#21]

(44) BroadcastHashJoin [codegen id : 11]
Left keys [1]: [c_customer_sk#30]
Right keys [1]: [c_customer_sk#21]
Join condition: None

(45) BroadcastExchange
Input [3]: [c_customer_sk#30, c_first_name#31, c_last_name#32]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=7]

(46) BroadcastHashJoin [codegen id : 13]
Left keys [1]: [cs_bill_customer_sk#2]
Right keys [1]: [c_customer_sk#30]
Join condition: None

(47) Project [codegen id : 13]
Output [5]: [cs_sold_date_sk#1, cs_quantity#4, cs_list_price#5, c_first_name#31, c_last_name#32]
Input [7]: [cs_sold_date_sk#1, cs_bill_customer_sk#2, cs_quantity#4, cs_list_price#5, c_customer_sk#30, c_first_name#31, c_last_name#32]

(48) ReusedExchange [Reuses operator id: 81]
Output [1]: [d_date_sk#33]

(49) BroadcastHashJoin [codegen id : 13]
Left keys [1]: [cs_sold_date_sk#1]
Right keys [1]: [d_date_sk#33]
Join condition: None

(50) Project [codegen id : 13]
Output [4]: [cs_quantity#4, cs_list_price#5, c_first_name#31, c_last_name#32]
Input [6]: [cs_sold_date_sk#1, cs_quantity#4, cs_list_price#5, c_first_name#31, c_last_name#32, d_date_sk#33]

(51) HashAggregate [codegen id : 13]
Input [4]: [cs_quantity#4, cs_list_price#5, c_first_name#31, c_last_name#32]
Keys [2]: [c_last_name#32, c_first_name#31]
Functions [1]: [partial_sum(CheckOverflow((promote_precision(cast(cs_quantity#4 as decimal(12,2))) * promote_precision(cast(cs_list_price#5 as decimal(12,2)))), DecimalType(18,2)))]
Aggregate Attributes [2]: [sum#34, isEmpty#35]
Results [4]: [c_last_name#32, c_first_name#31, sum#36, isEmpty#37]

(52) Exchange
Input [4]: [c_last_name#32, c_first_name#31, sum#36, isEmpty#37]
Arguments: hashpartitioning(c_last_name#32, c_first_name#31, 5), ENSURE_REQUIREMENTS, [plan_id=8]

(53) HashAggregate [codegen id : 14]
Input [4]: [c_last_name#32, c_first_name#31, sum#36, isEmpty#37]
Keys [2]: [c_last_name#32, c_first_name#31]
Functions [1]: [sum(CheckOverflow((promote_precision(cast(cs_quantity#4 as decimal(12,2))) * promote_precision(cast(cs_list_price#5 as decimal(12,2)))), DecimalType(18,2)))]
Aggregate Attributes [1]: [sum(CheckOverflow((promote_precision(cast(cs_quantity#4 as decimal(12,2))) * promote_precision(cast(cs_list_price#5 as decimal(12,2)))), DecimalType(18,2)))#38]
Results [3]: [c_last_name#32, c_first_name#31, sum(CheckOverflow((promote_precision(cast(cs_quantity#4 as decimal(12,2))) * promote_precision(cast(cs_list_price#5 as decimal(12,2)))), DecimalType(18,2)))#38 AS sales#39]

(54) BatchScan spark_catalog.default.web_sales
Output [5]: [ws_sold_date_sk#40, ws_item_sk#41, ws_bill_customer_sk#42, ws_quantity#43, ws_list_price#44]
spark_catalog.default.web_sales [scan class = SparkBatchQueryScan] [filters=ws_bill_customer_sk IS NOT NULL, ws_sold_date_sk IS NOT NULL], [runtimeFilters=[]], caseSensitive=false,[ Broadcast Var UNUSED =]

(55) Filter [codegen id : 27]
Input [5]: [ws_sold_date_sk#40, ws_item_sk#41, ws_bill_customer_sk#42, ws_quantity#43, ws_list_price#44]
Condition : (isnotnull(ws_bill_customer_sk#42) AND isnotnull(ws_sold_date_sk#40))

(56) Project [codegen id : 27]
Output [5]: [ws_sold_date_sk#40, ws_item_sk#41, ws_bill_customer_sk#42, ws_quantity#43, ws_list_price#44]
Input [5]: [ws_sold_date_sk#40, ws_item_sk#41, ws_bill_customer_sk#42, ws_quantity#43, ws_list_price#44]

(57) ReusedExchange [Reuses operator id: 21]
Output [1]: [item_sk#16]

(58) BroadcastHashJoin [codegen id : 27]
Left keys [1]: [ws_item_sk#41]
Right keys [1]: [item_sk#16]
Join condition: None

(59) Project [codegen id : 27]
Output [4]: [ws_sold_date_sk#40, ws_bill_customer_sk#42, ws_quantity#43, ws_list_price#44]
Input [5]: [ws_sold_date_sk#40, ws_item_sk#41, ws_bill_customer_sk#42, ws_quantity#43, ws_list_price#44]

(60) ReusedExchange [Reuses operator id: 38]
Output [1]: [c_customer_sk#21]

(61) BroadcastHashJoin [codegen id : 27]
Left keys [1]: [ws_bill_customer_sk#42]
Right keys [1]: [c_customer_sk#21]
Join condition: None

(62) BatchScan spark_catalog.default.customer
Output [3]: [c_customer_sk#45, c_first_name#46, c_last_name#47]
spark_catalog.default.customer [scan class = SparkBatchQueryScan] [filters=c_customer_sk IS NOT NULL], [runtimeFilters=[]], caseSensitive=false,[ Broadcast Var UNUSED =]

(63) Filter [codegen id : 25]
Input [3]: [c_customer_sk#45, c_first_name#46, c_last_name#47]
Condition : isnotnull(c_customer_sk#45)

(64) Project [codegen id : 25]
Output [3]: [c_customer_sk#45, c_first_name#46, c_last_name#47]
Input [3]: [c_customer_sk#45, c_first_name#46, c_last_name#47]

(65) ReusedExchange [Reuses operator id: 38]
Output [1]: [c_customer_sk#21]

(66) BroadcastHashJoin [codegen id : 25]
Left keys [1]: [c_customer_sk#45]
Right keys [1]: [c_customer_sk#21]
Join condition: None

(67) BroadcastExchange
Input [3]: [c_customer_sk#45, c_first_name#46, c_last_name#47]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=9]

(68) BroadcastHashJoin [codegen id : 27]
Left keys [1]: [ws_bill_customer_sk#42]
Right keys [1]: [c_customer_sk#45]
Join condition: None

(69) Project [codegen id : 27]
Output [5]: [ws_sold_date_sk#40, ws_quantity#43, ws_list_price#44, c_first_name#46, c_last_name#47]
Input [7]: [ws_sold_date_sk#40, ws_bill_customer_sk#42, ws_quantity#43, ws_list_price#44, c_customer_sk#45, c_first_name#46, c_last_name#47]

(70) ReusedExchange [Reuses operator id: 81]
Output [1]: [d_date_sk#48]

(71) BroadcastHashJoin [codegen id : 27]
Left keys [1]: [ws_sold_date_sk#40]
Right keys [1]: [d_date_sk#48]
Join condition: None

(72) Project [codegen id : 27]
Output [4]: [ws_quantity#43, ws_list_price#44, c_first_name#46, c_last_name#47]
Input [6]: [ws_sold_date_sk#40, ws_quantity#43, ws_list_price#44, c_first_name#46, c_last_name#47, d_date_sk#48]

(73) HashAggregate [codegen id : 27]
Input [4]: [ws_quantity#43, ws_list_price#44, c_first_name#46, c_last_name#47]
Keys [2]: [c_last_name#47, c_first_name#46]
Functions [1]: [partial_sum(CheckOverflow((promote_precision(cast(ws_quantity#43 as decimal(12,2))) * promote_precision(cast(ws_list_price#44 as decimal(12,2)))), DecimalType(18,2)))]
Aggregate Attributes [2]: [sum#49, isEmpty#50]
Results [4]: [c_last_name#47, c_first_name#46, sum#51, isEmpty#52]

(74) Exchange
Input [4]: [c_last_name#47, c_first_name#46, sum#51, isEmpty#52]
Arguments: hashpartitioning(c_last_name#47, c_first_name#46, 5), ENSURE_REQUIREMENTS, [plan_id=10]

(75) HashAggregate [codegen id : 28]
Input [4]: [c_last_name#47, c_first_name#46, sum#51, isEmpty#52]
Keys [2]: [c_last_name#47, c_first_name#46]
Functions [1]: [sum(CheckOverflow((promote_precision(cast(ws_quantity#43 as decimal(12,2))) * promote_precision(cast(ws_list_price#44 as decimal(12,2)))), DecimalType(18,2)))]
Aggregate Attributes [1]: [sum(CheckOverflow((promote_precision(cast(ws_quantity#43 as decimal(12,2))) * promote_precision(cast(ws_list_price#44 as decimal(12,2)))), DecimalType(18,2)))#53]
Results [3]: [c_last_name#47, c_first_name#46, sum(CheckOverflow((promote_precision(cast(ws_quantity#43 as decimal(12,2))) * promote_precision(cast(ws_list_price#44 as decimal(12,2)))), DecimalType(18,2)))#53 AS sales#54]

(76) Union

(77) TakeOrderedAndProject
Input [3]: [c_last_name#32, c_first_name#31, sales#39]
Arguments: 100, [c_last_name#32 ASC NULLS FIRST, c_first_name#31 ASC NULLS FIRST, sales#39 ASC NULLS FIRST], [c_last_name#32, c_first_name#31, sales#39]

===== Subqueries =====

Subquery:1 Hosting operator id = 1 Hosting Expression = cs_sold_date_sk#1 IN dynamicpruning#55
BroadcastExchange (81)
+- * Project (80)
   +- * Filter (79)
      +- BatchScan spark_catalog.default.date_dim (78)


(78) BatchScan spark_catalog.default.date_dim
Output [3]: [d_date_sk#33, d_year#56, d_moy#57]
spark_catalog.default.date_dim [scan class = SparkBatchQueryScan] [filters=d_year IS NOT NULL, d_moy IS NOT NULL, d_year = 2000, d_moy = 2, d_date_sk IS NOT NULL], [runtimeFilters=[]], caseSensitive=false,[ Broadcast Var UNUSED =]

(79) Filter [codegen id : 1]
Input [3]: [d_date_sk#33, d_year#56, d_moy#57]
Condition : ((((isnotnull(d_year#56) AND isnotnull(d_moy#57)) AND (d_year#56 = 2000)) AND (d_moy#57 = 2)) AND isnotnull(d_date_sk#33))

(80) Project [codegen id : 1]
Output [1]: [d_date_sk#33]
Input [3]: [d_date_sk#33, d_year#56, d_moy#57]

(81) BroadcastExchange
Input [1]: [d_date_sk#33]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=11]

Subquery:2 Hosting operator id = 4 Hosting Expression = ss_sold_date_sk#6 IN dynamicpruning#58
BroadcastExchange (85)
+- * Project (84)
   +- * Filter (83)
      +- BatchScan spark_catalog.default.date_dim (82)


(82) BatchScan spark_catalog.default.date_dim
Output [3]: [d_date_sk#8, d_date#9, d_year#59]
spark_catalog.default.date_dim [scan class = SparkBatchQueryScan] [filters=d_year IN (2000, 2001, 2002, 2003), d_date_sk IS NOT NULL], [runtimeFilters=[]], caseSensitive=false,[ Broadcast Var UNUSED =]

(83) Filter [codegen id : 1]
Input [3]: [d_date_sk#8, d_date#9, d_year#59]
Condition : (d_year#59 IN (2000,2001,2002,2003) AND isnotnull(d_date_sk#8))

(84) Project [codegen id : 1]
Output [2]: [d_date_sk#8, d_date#9]
Input [3]: [d_date_sk#8, d_date#9, d_year#59]

(85) BroadcastExchange
Input [2]: [d_date_sk#8, d_date#9]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=12]

Subquery:3 Hosting operator id = 36 Hosting Expression = Subquery scalar-subquery#28, [id=#29]
* HashAggregate (100)
+- Exchange (99)
   +- * HashAggregate (98)
      +- * HashAggregate (97)
         +- Exchange (96)
            +- * HashAggregate (95)
               +- * Project (94)
                  +- * BroadcastHashJoin Inner BuildRight (93)
                     :- * Project (91)
                     :  +- * BroadcastHashJoin Inner BuildRight (90)
                     :     :- * Project (88)
                     :     :  +- * Filter (87)
                     :     :     +- BatchScan spark_catalog.default.store_sales (86)
                     :     +- ReusedExchange (89)
                     +- ReusedExchange (92)


(86) BatchScan spark_catalog.default.store_sales
Output [4]: [ss_sold_date_sk#60, ss_customer_sk#61, ss_quantity#62, ss_sales_price#63]
spark_catalog.default.store_sales [scan class = SparkBatchQueryScan] [filters=ss_customer_sk IS NOT NULL, ss_sold_date_sk IS NOT NULL], [runtimeFilters=[]], caseSensitive=false,[ Broadcast Var UNUSED =]

(87) Filter [codegen id : 3]
Input [4]: [ss_sold_date_sk#60, ss_customer_sk#61, ss_quantity#62, ss_sales_price#63]
Condition : (isnotnull(ss_customer_sk#61) AND isnotnull(ss_sold_date_sk#60))

(88) Project [codegen id : 3]
Output [4]: [ss_sold_date_sk#60, ss_customer_sk#61, ss_quantity#62, ss_sales_price#63]
Input [4]: [ss_sold_date_sk#60, ss_customer_sk#61, ss_quantity#62, ss_sales_price#63]

(89) ReusedExchange [Reuses operator id: 30]
Output [1]: [c_customer_sk#64]

(90) BroadcastHashJoin [codegen id : 3]
Left keys [1]: [ss_customer_sk#61]
Right keys [1]: [c_customer_sk#64]
Join condition: None

(91) Project [codegen id : 3]
Output [4]: [ss_sold_date_sk#60, ss_quantity#62, ss_sales_price#63, c_customer_sk#64]
Input [5]: [ss_sold_date_sk#60, ss_customer_sk#61, ss_quantity#62, ss_sales_price#63, c_customer_sk#64]

(92) ReusedExchange [Reuses operator id: 104]
Output [1]: [d_date_sk#65]

(93) BroadcastHashJoin [codegen id : 3]
Left keys [1]: [ss_sold_date_sk#60]
Right keys [1]: [d_date_sk#65]
Join condition: None

(94) Project [codegen id : 3]
Output [3]: [ss_quantity#62, ss_sales_price#63, c_customer_sk#64]
Input [5]: [ss_sold_date_sk#60, ss_quantity#62, ss_sales_price#63, c_customer_sk#64, d_date_sk#65]

(95) HashAggregate [codegen id : 3]
Input [3]: [ss_quantity#62, ss_sales_price#63, c_customer_sk#64]
Keys [1]: [c_customer_sk#64]
Functions [1]: [partial_sum(CheckOverflow((promote_precision(cast(ss_quantity#62 as decimal(12,2))) * promote_precision(cast(ss_sales_price#63 as decimal(12,2)))), DecimalType(18,2)))]
Aggregate Attributes [2]: [sum#66, isEmpty#67]
Results [3]: [c_customer_sk#64, sum#68, isEmpty#69]

(96) Exchange
Input [3]: [c_customer_sk#64, sum#68, isEmpty#69]
Arguments: hashpartitioning(c_customer_sk#64, 5), ENSURE_REQUIREMENTS, [plan_id=13]

(97) HashAggregate [codegen id : 4]
Input [3]: [c_customer_sk#64, sum#68, isEmpty#69]
Keys [1]: [c_customer_sk#64]
Functions [1]: [sum(CheckOverflow((promote_precision(cast(ss_quantity#62 as decimal(12,2))) * promote_precision(cast(ss_sales_price#63 as decimal(12,2)))), DecimalType(18,2)))]
Aggregate Attributes [1]: [sum(CheckOverflow((promote_precision(cast(ss_quantity#62 as decimal(12,2))) * promote_precision(cast(ss_sales_price#63 as decimal(12,2)))), DecimalType(18,2)))#70]
Results [1]: [sum(CheckOverflow((promote_precision(cast(ss_quantity#62 as decimal(12,2))) * promote_precision(cast(ss_sales_price#63 as decimal(12,2)))), DecimalType(18,2)))#70 AS csales#71]

(98) HashAggregate [codegen id : 4]
Input [1]: [csales#71]
Keys: []
Functions [1]: [partial_max(csales#71)]
Aggregate Attributes [1]: [max#72]
Results [1]: [max#73]

(99) Exchange
Input [1]: [max#73]
Arguments: SinglePartition, ENSURE_REQUIREMENTS, [plan_id=14]

(100) HashAggregate [codegen id : 5]
Input [1]: [max#73]
Keys: []
Functions [1]: [max(csales#71)]
Aggregate Attributes [1]: [max(csales#71)#74]
Results [1]: [max(csales#71)#74 AS tpcds_cmax#75]

Subquery:4 Hosting operator id = 86 Hosting Expression = ss_sold_date_sk#60 IN dynamicpruning#76
BroadcastExchange (104)
+- * Project (103)
   +- * Filter (102)
      +- BatchScan spark_catalog.default.date_dim (101)


(101) BatchScan spark_catalog.default.date_dim
Output [2]: [d_date_sk#65, d_year#77]
spark_catalog.default.date_dim [scan class = SparkBatchQueryScan] [filters=d_year IN (2000, 2001, 2002, 2003), d_date_sk IS NOT NULL], [runtimeFilters=[]], caseSensitive=false,[ Broadcast Var UNUSED =]

(102) Filter [codegen id : 1]
Input [2]: [d_date_sk#65, d_year#77]
Condition : (d_year#77 IN (2000,2001,2002,2003) AND isnotnull(d_date_sk#65))

(103) Project [codegen id : 1]
Output [1]: [d_date_sk#65]
Input [2]: [d_date_sk#65, d_year#77]

(104) BroadcastExchange
Input [1]: [d_date_sk#65]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=15]

Subquery:5 Hosting operator id = 54 Hosting Expression = ws_sold_date_sk#40 IN dynamicpruning#55


