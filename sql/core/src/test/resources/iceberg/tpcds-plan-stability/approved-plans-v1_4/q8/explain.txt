== Physical Plan ==
TakeOrderedAndProject (42)
+- * HashAggregate (41)
   +- Exchange (40)
      +- * HashAggregate (39)
         +- * Project (38)
            +- * BroadcastHashJoin Inner BuildRight (37)
               :- * Project (12)
               :  +- * BroadcastHashJoin Inner BuildRight (11)
               :     :- * Project (6)
               :     :  +- * BroadcastHashJoin Inner BuildRight (5)
               :     :     :- * Project (3)
               :     :     :  +- * Filter (2)
               :     :     :     +- BatchScan spark_catalog.default.store_sales (1)
               :     :     +- ReusedExchange (4)
               :     +- BroadcastExchange (10)
               :        +- * Project (9)
               :           +- * Filter (8)
               :              +- BatchScan spark_catalog.default.store (7)
               +- BroadcastExchange (36)
                  +- * HashAggregate (35)
                     +- Exchange (34)
                        +- * HashAggregate (33)
                           +- * Project (32)
                              +- * BroadcastHashJoin LeftSemi BuildRight (31)
                                 :- * Project (15)
                                 :  +- * Filter (14)
                                 :     +- BatchScan spark_catalog.default.customer_address (13)
                                 +- BroadcastExchange (30)
                                    +- * Project (29)
                                       +- * Filter (28)
                                          +- * HashAggregate (27)
                                             +- Exchange (26)
                                                +- * HashAggregate (25)
                                                   +- * Project (24)
                                                      +- * BroadcastHashJoin Inner BuildRight (23)
                                                         :- * Project (18)
                                                         :  +- * Filter (17)
                                                         :     +- BatchScan spark_catalog.default.customer_address (16)
                                                         +- BroadcastExchange (22)
                                                            +- * Project (21)
                                                               +- * Filter (20)
                                                                  +- BatchScan spark_catalog.default.customer (19)


(1) BatchScan spark_catalog.default.store_sales
Output [3]: [ss_sold_date_sk#1, ss_store_sk#2, ss_net_profit#3]
spark_catalog.default.store_sales [scan class = SparkBatchQueryScan] [filters=ss_sold_date_sk IS NOT NULL, ss_store_sk IS NOT NULL], [runtimeFilters=[]], caseSensitive=false,[ Broadcast Var UNUSED =]

(2) Filter [codegen id : 8]
Input [3]: [ss_sold_date_sk#1, ss_store_sk#2, ss_net_profit#3]
Condition : (isnotnull(ss_sold_date_sk#1) AND isnotnull(ss_store_sk#2))

(3) Project [codegen id : 8]
Output [3]: [ss_sold_date_sk#1, ss_store_sk#2, ss_net_profit#3]
Input [3]: [ss_sold_date_sk#1, ss_store_sk#2, ss_net_profit#3]

(4) ReusedExchange [Reuses operator id: 46]
Output [1]: [d_date_sk#4]

(5) BroadcastHashJoin [codegen id : 8]
Left keys [1]: [ss_sold_date_sk#1]
Right keys [1]: [d_date_sk#4]
Join condition: None

(6) Project [codegen id : 8]
Output [2]: [ss_store_sk#2, ss_net_profit#3]
Input [4]: [ss_sold_date_sk#1, ss_store_sk#2, ss_net_profit#3, d_date_sk#4]

(7) BatchScan spark_catalog.default.store
Output [3]: [s_store_sk#5, s_store_name#6, s_zip#7]
spark_catalog.default.store [scan class = SparkBatchQueryScan] [filters=s_store_sk IS NOT NULL, s_zip IS NOT NULL], [runtimeFilters=[]], caseSensitive=false,[ Broadcast Var UNUSED =]

(8) Filter [codegen id : 2]
Input [3]: [s_store_sk#5, s_store_name#6, s_zip#7]
Condition : (isnotnull(s_store_sk#5) AND isnotnull(s_zip#7))

(9) Project [codegen id : 2]
Output [3]: [s_store_sk#5, s_store_name#6, s_zip#7]
Input [3]: [s_store_sk#5, s_store_name#6, s_zip#7]

(10) BroadcastExchange
Input [3]: [s_store_sk#5, s_store_name#6, s_zip#7]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=1]

(11) BroadcastHashJoin [codegen id : 8]
Left keys [1]: [ss_store_sk#2]
Right keys [1]: [s_store_sk#5]
Join condition: None

(12) Project [codegen id : 8]
Output [3]: [ss_net_profit#3, s_store_name#6, s_zip#7]
Input [5]: [ss_store_sk#2, ss_net_profit#3, s_store_sk#5, s_store_name#6, s_zip#7]

(13) BatchScan spark_catalog.default.customer_address
Output [1]: [ca_zip#8]
spark_catalog.default.customer_address [scan class = SparkBatchQueryScan] [filters=], [runtimeFilters=[]], caseSensitive=false,[ Broadcast Var UNUSED =]

(14) Filter [codegen id : 6]
Input [1]: [ca_zip#8]
Condition : (substr(ca_zip#8, 1, 5) INSET 10144, 10336, 10390, 10445, 10516, 10567, 11101, 11356, 11376, 11489, 11634, 11928, 12305, 13354, 13375, 13376, 13394, 13595, 13695, 13955, 14060, 14089, 14171, 14328, 14663, 14867, 14922, 15126, 15146, 15371, 15455, 15559, 15723, 15734, 15765, 15798, 15882, 16021, 16725, 16807, 17043, 17183, 17871, 17879, 17920, 18119, 18270, 18376, 18383, 18426, 18652, 18767, 18799, 18840, 18842, 18845, 18906, 19430, 19505, 19512, 19515, 19736, 19769, 19849, 20004, 20260, 20548, 21076, 21195, 21286, 21309, 21337, 21756, 22152, 22245, 22246, 22351, 22437, 22461, 22685, 22744, 22752, 22927, 23006, 23470, 23932, 23968, 24128, 24206, 24317, 24610, 24671, 24676, 24996, 25003, 25103, 25280, 25486, 25631, 25733, 25782, 25858, 25989, 26065, 26105, 26231, 26233, 26653, 26689, 26859, 27068, 27156, 27385, 27700, 28286, 28488, 28545, 28577, 28587, 28709, 28810, 28898, 28915, 29178, 29741, 29839, 30010, 30122, 30431, 30450, 30469, 30625, 30903, 31016, 31029, 31387, 31671, 31880, 32213, 32754, 33123, 33282, 33515, 33786, 34102, 34322, 34425, 35258, 35458, 35474, 35576, 35850, 35942, 36233, 36420, 36446, 36495, 36634, 37125, 37126, 37930, 38122, 38193, 38415, 38607, 38935, 39127, 39192, 39371, 39516, 39736, 39861, 39972, 40081, 40162, 40558, 40604, 41248, 41367, 41368, 41766, 41918, 42029, 42666, 42961, 43285, 43848, 43933, 44165, 44438, 45200, 45266, 45375, 45549, 45692, 45721, 45748, 46081, 46136, 46820, 47305, 47537, 47770, 48033, 48425, 48583, 49130, 49156, 49448, 50016, 50298, 50308, 50412, 51061, 51103, 51200, 51211, 51622, 51649, 51650, 51798, 51949, 52867, 53179, 53268, 53535, 53672, 54364, 54601, 54917, 55253, 55307, 55565, 56240, 56458, 56529, 56571, 56575, 56616, 56691, 56910, 57047, 57647, 57665, 57834, 57855, 58048, 58058, 58078, 58263, 58470, 58943, 59166, 59402, 60099, 60279, 60576, 61265, 61547, 61810, 61860, 62377, 62496, 62878, 62971, 63089, 63193, 63435, 63792, 63837, 63981, 64034, 64147, 64457, 64528, 64544, 65084, 65164, 66162, 66708, 66864, 67030, 67301, 67467, 67473, 67853, 67875, 67897, 68014, 68100, 68101, 68309, 68341, 68621, 68786, 68806, 68880, 68893, 68908, 69035, 69399, 69913, 69952, 70372, 70466, 70738, 71256, 71286, 71791, 71954, 72013, 72151, 72175, 72305, 72325, 72425, 72550, 72823, 73134, 73171, 73241, 73273, 73520, 73650, 74351, 75691, 76107, 76231, 76232, 76614, 76638, 76698, 77191, 77556, 77610, 77721, 78451, 78567, 78668, 78890, 79077, 79777, 79994, 81019, 81096, 81312, 81426, 82136, 82276, 82636, 83041, 83144, 83444, 83849, 83921, 83926, 83933, 84093, 84935, 85816, 86057, 86198, 86284, 86379, 87343, 87501, 87816, 88086, 88190, 88424, 88885, 89091, 89360, 90225, 90257, 90578, 91068, 91110, 91137, 91393, 92712, 94167, 94627, 94898, 94945, 94983, 96451, 96576, 96765, 96888, 96976, 97189, 97789, 98025, 98235, 98294, 98359, 98569, 99076, 99543 AND isnotnull(substr(ca_zip#8, 1, 5)))

(15) Project [codegen id : 6]
Output [1]: [ca_zip#8]
Input [1]: [ca_zip#8]

(16) BatchScan spark_catalog.default.customer_address
Output [2]: [ca_address_sk#9, ca_zip#10]
spark_catalog.default.customer_address [scan class = SparkBatchQueryScan] [filters=ca_address_sk IS NOT NULL], [runtimeFilters=[]], caseSensitive=false,[ Broadcast Var UNUSED =]

(17) Filter [codegen id : 4]
Input [2]: [ca_address_sk#9, ca_zip#10]
Condition : isnotnull(ca_address_sk#9)

(18) Project [codegen id : 4]
Output [2]: [ca_address_sk#9, ca_zip#10]
Input [2]: [ca_address_sk#9, ca_zip#10]

(19) BatchScan spark_catalog.default.customer
Output [2]: [c_current_addr_sk#11, c_preferred_cust_flag#12]
spark_catalog.default.customer [scan class = SparkBatchQueryScan] [filters=c_preferred_cust_flag IS NOT NULL, c_preferred_cust_flag = 'Y', c_current_addr_sk IS NOT NULL], [runtimeFilters=[]], caseSensitive=false,[ Broadcast Var UNUSED =]

(20) Filter [codegen id : 3]
Input [2]: [c_current_addr_sk#11, c_preferred_cust_flag#12]
Condition : ((isnotnull(c_preferred_cust_flag#12) AND (c_preferred_cust_flag#12 = Y)) AND isnotnull(c_current_addr_sk#11))

(21) Project [codegen id : 3]
Output [1]: [c_current_addr_sk#11]
Input [2]: [c_current_addr_sk#11, c_preferred_cust_flag#12]

(22) BroadcastExchange
Input [1]: [c_current_addr_sk#11]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=2]

(23) BroadcastHashJoin [codegen id : 4]
Left keys [1]: [ca_address_sk#9]
Right keys [1]: [c_current_addr_sk#11]
Join condition: None

(24) Project [codegen id : 4]
Output [1]: [ca_zip#10]
Input [3]: [ca_address_sk#9, ca_zip#10, c_current_addr_sk#11]

(25) HashAggregate [codegen id : 4]
Input [1]: [ca_zip#10]
Keys [1]: [ca_zip#10]
Functions [1]: [partial_count(1)]
Aggregate Attributes [1]: [count#13]
Results [2]: [ca_zip#10, count#14]

(26) Exchange
Input [2]: [ca_zip#10, count#14]
Arguments: hashpartitioning(ca_zip#10, 5), ENSURE_REQUIREMENTS, [plan_id=3]

(27) HashAggregate [codegen id : 5]
Input [2]: [ca_zip#10, count#14]
Keys [1]: [ca_zip#10]
Functions [1]: [count(1)]
Aggregate Attributes [1]: [count(1)#15]
Results [2]: [substr(ca_zip#10, 1, 5) AS ca_zip#16, count(1)#15 AS cnt#17]

(28) Filter [codegen id : 5]
Input [2]: [ca_zip#16, cnt#17]
Condition : (cnt#17 > 10)

(29) Project [codegen id : 5]
Output [1]: [ca_zip#16]
Input [2]: [ca_zip#16, cnt#17]

(30) BroadcastExchange
Input [1]: [ca_zip#16]
Arguments: HashedRelationBroadcastMode(List(coalesce(input[0, string, true], ), isnull(input[0, string, true])),false), [plan_id=4]

(31) BroadcastHashJoin [codegen id : 6]
Left keys [2]: [coalesce(substr(ca_zip#8, 1, 5), ), isnull(substr(ca_zip#8, 1, 5))]
Right keys [2]: [coalesce(ca_zip#16, ), isnull(ca_zip#16)]
Join condition: None

(32) Project [codegen id : 6]
Output [1]: [substr(ca_zip#8, 1, 5) AS ca_zip#18]
Input [1]: [ca_zip#8]

(33) HashAggregate [codegen id : 6]
Input [1]: [ca_zip#18]
Keys [1]: [ca_zip#18]
Functions: []
Aggregate Attributes: []
Results [1]: [ca_zip#18]

(34) Exchange
Input [1]: [ca_zip#18]
Arguments: hashpartitioning(ca_zip#18, 5), ENSURE_REQUIREMENTS, [plan_id=5]

(35) HashAggregate [codegen id : 7]
Input [1]: [ca_zip#18]
Keys [1]: [ca_zip#18]
Functions: []
Aggregate Attributes: []
Results [1]: [ca_zip#18]

(36) BroadcastExchange
Input [1]: [ca_zip#18]
Arguments: HashedRelationBroadcastMode(List(substr(input[0, string, true], 1, 2)),false), [plan_id=6]

(37) BroadcastHashJoin [codegen id : 8]
Left keys [1]: [substr(s_zip#7, 1, 2)]
Right keys [1]: [substr(ca_zip#18, 1, 2)]
Join condition: None

(38) Project [codegen id : 8]
Output [2]: [ss_net_profit#3, s_store_name#6]
Input [4]: [ss_net_profit#3, s_store_name#6, s_zip#7, ca_zip#18]

(39) HashAggregate [codegen id : 8]
Input [2]: [ss_net_profit#3, s_store_name#6]
Keys [1]: [s_store_name#6]
Functions [1]: [partial_sum(UnscaledValue(ss_net_profit#3))]
Aggregate Attributes [1]: [sum#19]
Results [2]: [s_store_name#6, sum#20]

(40) Exchange
Input [2]: [s_store_name#6, sum#20]
Arguments: hashpartitioning(s_store_name#6, 5), ENSURE_REQUIREMENTS, [plan_id=7]

(41) HashAggregate [codegen id : 9]
Input [2]: [s_store_name#6, sum#20]
Keys [1]: [s_store_name#6]
Functions [1]: [sum(UnscaledValue(ss_net_profit#3))]
Aggregate Attributes [1]: [sum(UnscaledValue(ss_net_profit#3))#21]
Results [2]: [s_store_name#6, MakeDecimal(sum(UnscaledValue(ss_net_profit#3))#21,17,2) AS sum(ss_net_profit)#22]

(42) TakeOrderedAndProject
Input [2]: [s_store_name#6, sum(ss_net_profit)#22]
Arguments: 100, [s_store_name#6 ASC NULLS FIRST], [s_store_name#6, sum(ss_net_profit)#22]

===== Subqueries =====

Subquery:1 Hosting operator id = 1 Hosting Expression = ss_sold_date_sk#1 IN dynamicpruning#23
BroadcastExchange (46)
+- * Project (45)
   +- * Filter (44)
      +- BatchScan spark_catalog.default.date_dim (43)


(43) BatchScan spark_catalog.default.date_dim
Output [3]: [d_date_sk#4, d_year#24, d_qoy#25]
spark_catalog.default.date_dim [scan class = SparkBatchQueryScan] [filters=d_qoy IS NOT NULL, d_year IS NOT NULL, d_qoy = 2, d_year = 1998, d_date_sk IS NOT NULL], [runtimeFilters=[]], caseSensitive=false,[ Broadcast Var UNUSED =]

(44) Filter [codegen id : 1]
Input [3]: [d_date_sk#4, d_year#24, d_qoy#25]
Condition : ((((isnotnull(d_qoy#25) AND isnotnull(d_year#24)) AND (d_qoy#25 = 2)) AND (d_year#24 = 1998)) AND isnotnull(d_date_sk#4))

(45) Project [codegen id : 1]
Output [1]: [d_date_sk#4]
Input [3]: [d_date_sk#4, d_year#24, d_qoy#25]

(46) BroadcastExchange
Input [1]: [d_date_sk#4]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=8]


